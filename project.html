<!DOCTYPE html>
<!-- saved from url=(0035)http://www.eng.auburn.edu/~bzl0056/ -->
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
        
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <meta name="description" content="">
        <meta name="author" content="">
        <title>Bo Liu</title>
        <!-- Bootstrap core CSS -->
        <link href="./liu-wp_files/bootstrap.css" rel="stylesheet">
        <!-- Custom styles for this template -->
        <link href="./liu-wp_files/jumbotron.css" rel="stylesheet">
        <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
        <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
      <script src="https://oss.maxcdn.com/libs/respond.js/1.3.0/respond.min.js"></script>
    <![endif]-->
    </head>
    <body>
        <div class="container">

            <img src="./liu-wp_files/trust-ai.png" width="200" height="200" class="text-right pull-right">

            <img src="./liu-wp_files/internet_of_things.png" width="200" height="220" class="text-right pull-right">

            <img src="./liu-wp_files/boliu.jpg" width="200" class="pull-right">

            <h3 class="text-left text-primary">Bo Liu</h3>
            <address style="display: block;"> <br>Associate Professor
            <br> Department of Computer Science
            <br> 3101P Shelby Center for Engineering Technology 
            <br> Auburn University
            <br> Auburn, AL 36849-5347
            <br>
            <br>
            Associate Editor, IEEE Trans. on Neural Networks and Learning Systems
            </address>
            <address style="display: block;">Email:<br> firstname(nospace)lastname AT schoolname DOT edu
                <!-- <br> bo.t.liu AT philips DOT com -->
            </address>
                
            <h4 class="text-left text-primary" style="display: block;"><a href="./files/BIO_boliu.txt"><strong>[Brief Bio]</strong>
            </a><a href="https://www.dropbox.com/s/q9anbydcrporduu/cv_BoLiu.pdf"><strong>[CV]</strong></a>
            <a href="https://scholar.google.com/citations?hl=en&amp;user=8MliTo4AAAAJ&amp;view_op=list_works&amp;sortby=pubdate"><strong>[Google Scholar]</strong></a>
            <a href="https://dblp.org/pers/hd/l/Liu_0006:Bo"><strong>[DBLP]</strong></a>
            </h4><br><br>
                
            <ul class="nav nav-tabs"> 
                <li>
                    <a href="index.html">Home</a>
                </li>                 
                <li>
                    <a href="publication.html">Publications</a>
                </li> 
                <li class="active">
                    <a href="project.html">Projects</a>
                </li> 
                <li>
                    <a href="teaching.html">Teaching</a>
                </li>  
                <li>
                    <a href="student.html">Student &amp; Enrollment</a>
                </li>               
            </ul>
        </div>
<br>



<div class="container">


<div class="container">
            <h4 class="text-left text-primary" style="display: block;">Selected Projects</h4>

I am interested in some fundamental problems of RL and AI, and fortunate enough to have some outcomes we are particularly proud of
<br><br>

<img src="./publication_files/1.png" width="800" height="300">                    
                   
<p></p><br>
<strong>Counterfactual Prediction and Control</strong>: Humans and robots learn to perceive and interact with the world via real-time interactions. Can they do this not by real-time interactions but by learning only from past experiences? This is challenging since the past experience may be very different from the current scenario, which is termed "counterfactual." 
<br>
<font color="#FF0000"><strong>Technical contributions:</strong></font>
<li>Off-policy stable prediction algorithms in sequential decision-making, and their sample complexity analysis.
</li>
<li>Off-policy policy gradient theorem with function approximation, and counterfactual density ratio estimation.
</li>
<font color="#FF0000"><strong>Publications:</strong></font> <br>
<a href="https://liubo-cs.github.io/files/c-2015-uai.pdf">[UAI'2015 best student paper award]</a> 
<a href="https://liubo-cs.github.io/files/c-2016-IJCAI_GTD.pdf">[IJCAI'2016]</a> 
<a href="https://jair.org/index.php/jair/article/view/11260/26455">[JAIR'2018]</a>       
<a href="https://liubo-cs.github.io/files/j-2018-ieee-tnn.pdf">[IEEE-TNN'2018]</a>
<a href="https://arxiv.org/pdf/1911.04384.pdf">[ICML'2020a (COFPAC)]</a>
<a href="https://arxiv.org/pdf/2001.11113.pdf">[ICML'2020b (GradientDICE)]</a>
<br>
<font color="#FF0000"><strong>Impact:</strong></font> <br>
<li>UAI Facebook Best Student Paper Award, 2015<a href="https://www.google.com/search?q=sridhar+mahadevan+rldm&rlz=1C5GCEM_enUS1019US1019&biw=1629&bih=842&tbm=vid&sxsrf=ALiCzsZgqUjKERxJyto5lmsYq4C1fqFsag%3A1662653448364&ei=CBQaY57wFa3k0PEPtLe3uA0&ved=0ahUKEwielLLhyoX6AhUtMjQIHbTbDdcQ4dUDCA0&uact=5&oq=sridhar+mahadevan+rldm&gs_lcp=Cg1nd3Mtd2l6LXZpZGVvEAMyBQgAEKIEMgcIABAeEKIEMgUIABCiBDIFCAAQogQyBQgAEKIEOgQIIxAnUKcDWNUNYKYPaABwAHgAgAF3iAH8BpIBAzkuMpgBAKABAcABAQ&sclient=gws-wiz-video">[video]</a></li>
<li>Results included in the classical textbook "Reinforcement Learning: An Introduction" (Sutton & Barto, 2nd edition)</li>
<li>More than 400 citations from worldwide</li>
<br> <br> <br> <br> <br> 

<img src="./publication_files/2.png" width="800" height="300">

<p></p><br>
<strong>Risk-Aware Control</strong>: Autonomous driving has become a billion-dollar business. An applicable autonomous driving system must be risk-aware to avoid accidents. Same for stock market investment, where risk management is critical in order not to go bankrupt. All these problems can be formulated as risk-aware control under uncertainty and stochasticity.  
<br>
<font color="#FF0000"><strong>Technical contributions:</strong></font>
<li>Mean-Variance optimization with sample complexity analysis.
</li>
<li>"Magic" meta-algorithms that can turn any off-the-shelf risk-oblivious ones into risk-aware.
</li>
<font color="#FF0000"><strong>Publications:</strong></font> <br>
<a href="https://arxiv.org/pdf/1809.02292.pdf">[NeurIPS'18]</a>
<a href="https://arxiv.org/pdf/2004.10888.pdf">[AAAI'2021]</a>
<br>
<font color="#FF0000"><strong>Impact:</strong></font> <br>
<li>Best Paper Award at AAMAS-22 13th OptLearnMAS Workshop, 2022</li>
<li>One of the most popular tutorials in UAI'2022</li>
<br> <br> <br> <br> <br> 

<img src="./publication_files/3.png" width="800" height="300"> 

<p></p><br>
<strong>Explainable and Reasonable AI</strong>: Existing AI is powerful and everywhere. But it is like a magic black-box: maybe you know what and how it will do, but you don't know "why". Does it matter to know "why"? Yes! Knowing "why" brings us confidence, and helps us understand AI better.
<br>
<font color="#FF0000"><strong>Technical contributions:</strong></font> 
<li>Explainable AI, decision-making, and reasoning.
</li>
<li>For complicated raw tasks, how to conduct explainable task decomposition into "primitive" subtasks and task reduction.
</li>
<font color="#FF0000"><strong>Publications:</strong></font> <br>
<a href="https://arxiv.org/pdf/1804.07779.pdf">[IJCAI'2018]</a>
<a href="https://arxiv.org/pdf/1811.00090.pdf">[AAAI'2019]</a>
<a href="https://arxiv.org/pdf/1909.09209.pdf"></a><a href="http://www.eng.auburn.edu/~bzl0056/">[ICLP'2019]</a> 
<a href="https://arxiv.org/pdf/2108.06080.pdf">[IEEE-TETCI'2021]</a>  
<a href="https://ebooks.iospress.nl/volumearticle/58850">[Neuro-Symbolic AI book chapter'2021]</a>         
<br><br>
        
<img src="./publication_files/4.png" width="800" height="300">    

<p></p><br>
<strong>Sparse RL</strong>: Sparsity is the eternal interest of statistics as it leads to robustness, simplicity, and interpretability of the learned model. So why not having sparsity in RL?:)
<br>
<font color="#FF0000"><strong>Technical contributions:</strong></font> 
<li>Reinforcement learning with first-order sparsity (e.g., proximal gradient and mirror descent), power series method (e.g., Krylov method), and linear program (e.g., Dantzig Selector).
</li>
<font color="#FF0000"><strong>Publications:</strong></font> <br>
<a href="https://liubo-cs.github.io/files/c-2010-nips.pdf">[NIPS'2010]</a>
<a href="https://liubo-cs.github.io/files/c-2012-nips.pdf">[NIPS'2012]</a>
<a href="https://liubo-cs.github.io/files/c-2012-uai.pdf">[UAI'2012]</a>
<a href="https://arxiv.org/pdf/1811.00958.pdf">[UAI'2016]</a> 
<a href="https://liubo-cs.github.io/files/c-2016-uglasso-aaai.pdf">[AAAI'2016]</a><br> 
<font color="#FF0000"><strong>Impact:</strong></font> <br>
<li>NIPS Spotlight Presentation, 2022<a href="http://videolectures.net/machine_liu_learning/">[video]</a></li>

<br> 
        
</li></div>

<br><br>

</body></html>
